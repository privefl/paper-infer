%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{xurl}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}
%\usepackage[font=small]{caption}

\renewcommand{\arraystretch}{1.3}

%\usepackage{xr}
%\externaldocument{paper-infer-supp}

%\linenumbers
%\doublespacing
\onehalfspacing
\usepackage[numbers,super]{natbib} \bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{graphicx}
\graphicspath{{../figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\usepackage{algorithm}
\usepackage{algpseudocode}

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother


\begin{document}
\setlength{\baselineskip}{1.2\baselineskip}


\title{Inferring disease architecture and predictive ability\\with LDpred2-auto}

\author{Florian Priv\'e,$^{\text{1,}*}$ Clara Albi\~nana,$^{\text{1}}$ Julyan Arbel,$^{\text{2}}$ Bogdan Pasaniuc,$^{\text{3,4,5,6}}$ and Bjarni J. Vilhj\'almsson$^{\text{1,7,8}}$}

\date{~ }
\maketitle

\noindent$^{\text{\sf 1}}$National Centre for Register-based Research, Aarhus University, Aarhus, Denmark. \\
\noindent$^{\text{\sf 2}}$Univ.\ Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France. \\
\noindent$^{\text{\sf 3}}$Bioinformatics Interdepartmental Program, University of California, Los Angeles, CA, USA. \\
\noindent$^{\text{\sf 4}}$Department of Human Genetics, David Geffen School of Medicine, University of California, Los Angeles, CA, USA. \\
\noindent$^{\text{\sf 5}}$Department of Pathology and Laboratory Medicine, David Geffen School of Medicine, University of California, Los Angeles, CA, USA. \\
\noindent$^{\text{\sf 6}}$Department of Computational Medicine, David Geffen School of Medicine, University of California, Los Angeles, CA, USA. \\
\noindent$^{\text{\sf 7}}$Bioinformatics Research Centre, Aarhus University, Aarhus, Denmark. \\
\noindent$^{\text{\sf 8}}$Novo Nordisk Foundation Center for Genomic Mechanisms of Disease, Broad Institute, Cambridge, MA, USA. \\
\noindent$^\ast$To whom correspondence should be addressed. \\

\noindent Contact: \url{florian.prive.21@gmail.com}

%\vspace*{6em}
\clearpage

\begin{abstract}
	
LDpred2 is a widely used Bayesian method for building polygenic scores (PGS). LDpred2-auto can infer the two parameters from the LDpred model, the SNP heritability $h^2$ and polygenicity $p$, so that it does not require an additional validation dataset to choose best-performing parameters. 
The main aim of this paper is to properly validate the use of LDpred2-auto for inferring multiple genetic parameters.
Here, we present a new version of LDpred2-auto that adds an optional third parameter $\alpha$ to its model, for modeling negative selection. We then validate the inference of these three parameters (or two, when using the previous model). We also show that LDpred2-auto provides per-variant probabilities of being causal that are well calibrated, and can therefore be used for fine-mapping purposes. We also introduce a formula to infer the out-of-sample predictive performance $r^2$ of the resulting PGS directly from the Gibbs sampler of LDpred2-auto. Finally, we extend the set of HapMap3 variants recommended to use with LDpred2 with 37\% more variants to improve the coverage of this set, and show that this new set of variants captures 12\% more heritability and provides 6\% more predictive performance, on average, in UK Biobank analyses.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\section*{Introduction}

Most traits and diseases in humans are heritable.
What differs is the genetic architecture of each trait that can be parameterized by three key terms: the heritability (i.e.\ the proportion of phenotypic variation explained by genetics), the polygenicity (i.e.\ the fraction of genomic variants that have a non-zero effect on the trait), and the causal effect distribution (i.e.\ how the effect size distribution varies across causal variants).
Some phenotypes, such as schizophrenia or height, are highly heritable and highly polygenic \cite[]{sullivan2003schizophrenia,yang2010common,oconnor2019extreme,trubetskoy2022mapping}.
Causal effects are larger when a trait is more heritable, and smaller when it is more polygenic.
As for the distribution of causal effects relative to their allele frequencies, it is often investigated through a single parameter, usually called $\alpha$ or $S$, to model the effect of negative selection on complex traits whereby variants with lower frequencies are expected to have higher causal effect sizes \cite[]{speed2012improved}.
In this model, the expected phenotypic variance explained by a genetic variant is proportional to $\big[f(1-f)\big]^\alpha$, where $f$ is the allele frequency of this variant.
Many methods have been developed to estimate the SNP heritability (referred to as $h^2$ for brevity) and polygenicity ($p$), either globally for the whole genome or locally for specific regions of the genome, as well as $\alpha$. 
These methods (non-exhaustively) include GCTA\cite{yang2011gcta} ($h^2$), BOLT-REML\cite{loh2015contrasting} ($h^2$ and $p$), LD Score regression\cite{bulik2015ld} ($h^2$), FINEMAP\cite{benner2016finemap} (per-variant $p$, also called posterior inclusion probabilities PIPs, used for fine-mapping), HESS\cite{shi2016contrasting} (local $h^2$), LDAK-SumHer\cite{speed2019sumher,speed2020evaluating} ($h^2$ and $\alpha$), S-LD4M\cite{oconnor2019extreme} ($p$), GRM-MAF-LD\cite{schoech2019quantification} ($\alpha$), SuSiE\cite{wang2020simple} (PIPs), SBayesS\cite{zeng2021widespread} ($h^2$, $p$, and a third parameter $S$, similar to $\alpha$), and BEAVR\cite{johnson2021estimation} (local $p$).
Not all methods have the same modeling assumptions; for example, LDAK-SumHer assumes a different prior than SBayesS and LDpred2-auto, and does not estimate all the same parameters. It can estimate the SNP heritability and $\alpha$. However, it cannot estimate the polygenicity nor the per-variant probabilities of being causal (since it inherently assumes an infinitesimal model, i.e.\ $p = 1$). Moreover, since it does not sample effects, it cannot be used to estimate the predictive performance $r^2$ with the formula we propose in this paper. 
 
As previously shown by \citep{daetwyler2008accuracy}, $h^2$ and $p$ can also be used to determine how well we can predict a phenotype from using genetic variants alone, with $r^2_\text{max} = h^2 \cdot r^2_{g\hat{g}} = \dfrac{h^2}{1 + (1 - r^2_\text{max}) \frac{M p}{N h^2}}$, where $r^2_\text{max}$ and $r^2_{g\hat{g}}$ are the maximum achievable squared correlations between the genetic predictor and respectively the phenotype and its genetic component, $N$ is the sample size, $M$ is the number of variants, so $M p$ is the number of causal variants. 
Such genetic predictors are called polygenic scores (PGS), and are getting closer to being included as part of existing clinical risk models for diseases \cite[]{torkamani2018personal,lambert2019towards,kumuthini2022clinical}.
LDpred2 is a widely used polygenic score method that can directly build PGS using resulting summary statistics from genome-wide associations studies (GWAS), making it highly applicable \cite[]{prive2020ldpred2,pain2021evaluation,kulm2021systematic}.
LDpred2 is a Bayesian approach that uses the SNP heritability $h^2$ and polygenicity $p$ as parameters of its model. LDpred2-auto, one variant of LDpred2, can directly estimate these two parameters from GWAS summary statistics, making it applicable even when no validation data is available for tuning these two model parameters \cite[]{prive2020ldpred2}.

The main aim of this paper is to properly validate the use of LDpred2-auto for inferring multiple genetic parameters.
Here we extend LDpred2-auto and show it is a reliable method for estimating $h^2$ (global and local), $p$ (also per-variant probabilities PIP used for fine-mapping purposes), and $\alpha$ (by extending its model to also include this third parameter).
So, on top of providing competitive PGS, LDpred2-auto can also provide all these estimates of genetic architecture. 
Moreover, we show how it can now also reliably estimate the predictive ability $r^2$ of PGS it derives, allowing for directly assessing the usefulness of the derived PGS, without requiring an independent test set.
An overview of what LDpred2-auto can now provide is presented in Figure \ref{fig:overview}.
Finally, we extend the set of HapMap3 variants recommended to use with LDpred2, which enables us to capture around 12\% more SNP heritability and achieve around 6\% more predictive performance $r^2$, on average, in UK Biobank analyses.
We call `HapMap3+' this extended set of 1,444,196 SNPs, and recommend using it when power is sufficient (i.e.\ with a large sample size, large $h^2$, and/or small $p$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[!htb]
	\centerline{\includegraphics[width=0.9\textwidth]{overview}}
	\caption{Overview of what LDpred2-auto can now provide. For individual CIs of polygenic scores, please refer to the work of \citep{ding2022large,ding2022polygenic}. HapMap3+ is the new extended set of 1,444,196 SNPs we introduce here (Methods), and now recommend using for LDpred2 when power is sufficient (i.e.\ with a large sample size, large $h^2$, and/or small $p$). CI means ``confidence interval'' (often called ``credible interval'' in a Bayesian setting). \label{fig:overview}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
\section*{Materials and Methods}

We have extensively used R packages bigstatsr and bigsnpr \cite[]{prive2017efficient} for analyzing large genetic data, packages from the future framework \cite[]{bengtsson2020unifying} for easy scheduling and parallelization of analyses on the HPC cluster, and packages from the tidyverse suite \cite[]{wickham2019welcome} for shaping and visualizing results.

\subsection*{Data for simulations}

For simulations, we use the UK Biobank imputed (BGEN) data, read as allele dosages with function \texttt{snp\_readBGEN} from R package bigsnpr \cite[]{bycroft2018uk,prive2017efficient}. 
We use the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2}.
Since we run lots of different models, we restrict the simulations to chromosomes 3, 6, 9, 12, 15, 18 and 21, resulting in a set of 322,805 SNPs.
We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (field 22020). These individuals are unrelated and have passed some quality control such as removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in \citep{bycroft2018uk}).
To get a set of genetically homogeneous individuals, we compute a robust Mahalanobis distance based on the first 16 PCs (field 22009) and further restrict individuals to those within a log-distance of 4.5 \cite[]{prive2020efficient}.  
This results in 356,409 individuals of Northwestern European ancestry.
We randomly sample 200,000 individuals to form a training set (to run the GWAS), and use the remaining individuals to form a test set (to evaluate the predictive models).

\subsection*{Data for the UK Biobank analyses}

We use the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2}, and the same 356,409 individuals of Northwestern European ancestry as in the simulations.
We randomly sample 50,000 individuals to form a test set (to evaluate the predictive models), and use the remaining individuals to form a training set (to run the GWAS).

We construct and use the same phenotypes as in \citep{prive2021high}.
About half of these consists of phecodes mapped from ICD10 and ICD9 codes using R package PheWAS \cite[]{carroll2014r,wu2019mapping}.
The other half consists of phenotypes defined in UKBB fields based on manual curation \cite[]{prive2021high}.
As covariates, we first recompute PCs for the homogeneous subset of individuals previously defined using function \texttt{snp\_autoSVD} from R package bigsnpr and keep four PCs based on visual inspection \cite[]{prive2017efficient,prive2020efficient}. We also use sex (field 22001), age (field 21022), birth date (combining fields 34 and 52) and deprivation index (field 189) as additional covariates (to a total of eight).

We use the LD matrix with independent LD blocks computed in \citep{prive2021identifying}.
We design two other LD matrices: one using a smaller random subset of 2000 individuals from the previously selected ones (which we call ``hm3\_small''), and one based on 10,000 individuals from around South Europe by using the ``Italy'' center defined in \citep{prive2021high} (``hm3\_altpop'').
We apply the optimal algorithm developed in \citep{prive2021optimal} to obtain independent LD blocks, as recommended in \citep{prive2021identifying}.
We finally define a fourth LD reference by extending the set of HapMap3 variants (see next Methods section) and using 20,000 individuals from the previously selected ones (``hm3\_plus'').

\subsection*{Extending the set of HapMap3 variants used}

The HapMap3 variants generally provide a good coverage of the whole genome.
We recall that the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2} is a subset of the original set of HapMap3 variants, which does not include duplicated positions (e.g.\ multi-allelic variants), nor ambiguous variants (e.g.\ `A' and `T', or `C' and `G'), and which includes SNPs only (e.g.\ no indel).
Here we propose to extend this set of 1,054,330 HapMap3 variants to make sure many genetic variants are well tagged by the extended set.
To design this new set, we first read all variants from the UK Biobank (UKBB) with a minor allele frequency (MAF) larger than 0.005 in the whole data (i.e.\ the MAF from the MFI files). 
There are around 11.5M such variants.
Then we restrict to unrelated UKBB individuals which are \textit{not} listed as White British (field 22006) and use these individuals of diverse ancestries \cite[]{bycroft2018uk,prive2021using} to compute all pairwise correlations between variants within a 1 Mb distance, restricting to squared correlations larger than 0.3.
Finally, we design an algorithm which aims at maximizing the tagging of all these variants read. We want to maximize $\sum_j \max_{k \in \text{HapMap3+}} r_{j,k}^2$, where $j$ spans the whole set of variants read, while $k$ spans the variants kept in the new set, which we call HapMap3+.
We start by including all previously used HapMap3 variants.
Then, for the sake of simplicity, we use a greedy approach, where we repeatedly include the variant which increases this sum most, until no variant improves it by more than 2. 
Note that we only allow non-ambiguous SNPs to be included.
This results in an extended set of 1,444,196 SNPs, of which we compute the LD matrix (within a 3 cM window) and apply the optimal algorithm developed in \citep{prive2021optimal} to obtain 431 independent LD blocks.
Since we use individuals of diverse ancestries for computing the pairwise variant correlations used for constructing this extended set of variants, we expect this new set of variants to be beneficial across diverse ancestries.
Indeed, from the 11.5M variants we aimed at tagging, 82.1\% (respectively 69.1\%), 80.0\% (resp.\ 66.7\%), 79.3\% (resp.\ 66.1\%), 75.4\% (resp.\ 65.3\%), and 66.6\% (resp.\ 48.6\%) are tagged at $r^2 > 50\%$ (resp.\ $r^2 > 80\%$) by at least one HapMap3+ variant, respectively in North-West Europeans, Middle Easterns, South Asians, East Asians, and West Africans (results extrapolated from variants in chromosome 22).

\subsection*{Optional extended model and inference with LDpred2-auto}

LDpred2 originally assumed the following model for effect sizes,
\begin{equation}\label{eq:prev_model}
\beta_j = S_j \gamma_j \sim \left\{
\begin{array}{ll}
\mathcal N\left(0,~\dfrac{h^2}{M p}\right) & \mbox{with probability $p$,} \\
0 & \mbox{otherwise,}
\end{array}
\right.
\end{equation}
where $p$ is the proportion of causal variants, $M$ the number of variants, $h^2$ the (SNP) heritability, $\boldsymbol{\gamma}$ the effect sizes on the allele scale, $\boldsymbol{S}$ the standard deviations of the genotypes, and $\boldsymbol{\beta}$ the effects of the scaled genotypes \cite[]{prive2020ldpred2}.
In LDpred2-auto, $p$ and $h^2$ are directly estimated within the Gibbs sampler, as opposed to testing several values of $p$ and $h^2$ from a grid of hyper-parameters (as in LDpred2-grid). 
This makes LDpred2-auto a method free of hyper-parameters which can therefore be applied directly without requiring a validation dataset to choose best-performing hyper-parameters \cite[]{prive2020ldpred2}.
$h^2$ is estimated by $\boldsymbol{\beta}^T \boldsymbol{R} \boldsymbol{\beta}$, where $\boldsymbol{R}$ is the correlation matrix between variants and $\boldsymbol{\beta}$ is a vector of causal effect sizes (after scaling) from one iteration of the Gibbs sampler.  
As for $p$, it is sampled from $\text{Beta}(1 + M_c, 1 + M - M_c)$, where $M_c = \sum_j(\beta_j \neq 0)$.
Note a small change, we now sample $p$ from $\text{Beta}(1 + M_c / \bar{l^2}, 1 + (M - M_c) / \bar{l^2})$, where $\bar{l^2}$ is the average LD score, to add more variability in the sampling in order to account for a reduced effective number of (independent) variants.

Here we provide a extended model and sampling scheme for LDpred2-auto that can be optionally used by setting parameter \texttt{use\_MLE = TRUE} (otherwise it is run as described in the previous paragraph when using \texttt{use\_MLE = FALSE}).
In this new option, we extend LDpred2-auto with a third parameter $\alpha$ that controls the relationship between minor allele frequencies (or equivalently, standard deviations) of genotypes and expected effect sizes; the model becomes
\begin{equation}\label{eq:new_model}
\beta_j = S_j \gamma_j \sim \left\{
\begin{array}{ll}
\mathcal N \big( 0,~\sigma_\beta^2 \cdot (S_j^2)^{(\alpha + 1)} \big) & \mbox{with probability $p$,} \\
0 & \mbox{otherwise.}
\end{array}
\right.
\end{equation}
Therefore, it was earlier assumed that $\alpha = -1$ and $\sigma_\beta^2 = h^2 / (M p)$ in equation \eqref{eq:prev_model}. 
This extended model in equation \eqref{eq:new_model} is similar to the model assumed by SBayesS, where $\alpha$ is denoted by $S$ instead \cite[]{zeng2021widespread}. 
In SBayesS, $\alpha$ and $\sigma_\beta^2$ are estimated by maximizing the likelihood of the normal distribution (over the causal variants from the Gibbs sampler).
When using this 3-parameter model in LDpred2-auto, in order to add some sampling to these two parameters, we first sample causal variants with replacement before computing the maximum likelihood estimators. 
This maximum likelihood estimation (MLE) is implemented using R package roptim \cite[]{pan2020roptim}, and we bound the estimate of $\alpha$ to be between -1.5 and 0.5 (the default, but can be modified), and the estimate of $\sigma_\beta^2$ to be between 0.5 and 2 times the one from the previous iteration of the Gibbs sampler.
Note that we still estimate $h^2 = \boldsymbol{\beta}^T \boldsymbol{R} \boldsymbol{\beta}$, but that $h^2$ is not used in the variance of sampled effect sizes anymore (Equation \eqref{eq:new_model}). 
Note that, to get local heritability estimates (e.g.\ for a single LD block), this $h^2$ estimation ($\boldsymbol{\beta}^T \boldsymbol{R} \boldsymbol{\beta}$) is simply restricted to the variants from this LD block.
Finally, in both models and sampling schemes now implemented in LDpred2-auto, we now detect strong divergence when $\boldsymbol{\beta}^T \boldsymbol{\beta} > 2 \boldsymbol{\hat{\beta}}^T \boldsymbol{\hat{\beta}}$, where $\boldsymbol{\beta}$ is the vector of scaled effect sizes from one iteration of the Gibbs sampler and $\boldsymbol{\hat{\beta}}$ is the marginal scaled effect sizes; corresponding chains are stopped and missing values are returned for effect sizes and estimates of missing iterations.


\subsection*{Inference of predictive performance $r^2$}

To infer the out-of-sample predictive performance $r^2$ (and its CI) of the resulting PGS from LDpred2-auto, we use the distribution of $\boldsymbol{\beta_1}^T \boldsymbol{R} \boldsymbol{\beta_2}$, where $\boldsymbol{\beta_1}$ and $\boldsymbol{\beta_2}$ are two sampled vectors of causal effect sizes (after scaling) from two different chains of the Gibbs sampler.
Intuitively, if prediction is perfect then $\boldsymbol{\beta_1} = \boldsymbol{\beta_2}$ and $r^2 = h^2$; when power is very low, $\boldsymbol{\beta_1}$ and $\boldsymbol{\beta_2}$ are almost uncorrelated and $r^2 \approx 0$.
Others have proposed to estimate $r^2$ from a reference genotype set \cite[]{mak2017polygenic} or from an additional set of external GWAS summary statistics and LD reference \cite[]{pattee2020penalized,witteveen2022publicly}; here we only use the summary statistics that we input to LDpred2-auto.
These previous works have shown that $r^2$ can be approximated by $\big(\boldsymbol{\bar{\beta}}^T \boldsymbol{\hat{\beta}}_\text{test}\big)^2 / \big(\boldsymbol{\bar{\beta}}^T \boldsymbol{R} \boldsymbol{\bar{\beta}}\big)$ where $\boldsymbol{\bar{\beta}}$ and $\boldsymbol{\hat{\beta}}_\text{test}$ are respectively the predictive effects from the training set and the marginal effects from the test set (after scaling).
Note that $E[\boldsymbol{\beta_1}] = \boldsymbol{\bar{\beta}}$, $E[\boldsymbol{\beta_1}^T \boldsymbol{R} \boldsymbol{\beta_2}] = \boldsymbol{\bar{\beta}}^T \boldsymbol{R} \boldsymbol{\bar{\beta}}$, and, when the test sample has the same genetic ancestry as the GWAS used for training (to get the summary statistics), $E[\boldsymbol{R} \boldsymbol{\beta_2}] \approx \boldsymbol{\hat{\beta}}_\text{test}$.
Therefore, we propose to use $\boldsymbol{\beta_1}^T \boldsymbol{R} \boldsymbol{\beta_2}$ as a sample of $r^2$.
This can also be computed for a specific chain by taking two samples $\boldsymbol{\beta_1}$ and $\boldsymbol{\beta_2}$ that are far enough on the same chain to remove the possible autocorrelation. 
This is what we use for SBayesS here, and also as an alternative means for post-filtering chains for prediction (cf.\ next Methods section).
Note that \citep{ding2022large} investigated autocorrelation in LDpred2(-grid) and showed that it decays very quickly. Therefore picking two LDpred2-auto samples that are 100 iterations apart should be more than enough to ensure quasi-independence of these samples.

In this paper, we check this $r^2$ approximation using extensive simulations (across many genetic architectures) and real data analyses (across 248 different phenotypes).
These are compared to the partial-$r^2$ (on individual-level data from a separate test set). The partial correlation is computed with function \texttt{pcor} from R package bigstatsr, adjusting for the same eight covariates as in the GWAS, then squared (while keeping the sign). Corresponding 95\% confidence intervals are estimated through bootstrapping individual indices.


\subsection*{Post-filtering of chains in LDpred2-auto}

Because a Gibbs sampler can be unstable, with so many variants and with possible mismatches between e.g.\ the GWAS summary statistics and the LD reference used, we have always recommended to run multiple chains in LDpred2-auto, and post-filter some of them as quality control \cite[]{prive2020ldpred2}.
We originally proposed to filter chains by keeping the ones providing PGS with the largest variances. 
Then we tested an almost equivalent and simpler alternative \cite[]{prive2021identifying}, which is to keep only chains that provide top imputed marginal scaled effect sizes $\check{\beta} = R \bar{\beta}$, where $R$ is the correlation matrix and $\bar{\beta}$ are the PGS scaled effect sizes.
This is the default post-filtering of LDpred2-auto chains that we use here, for both prediction and inference.

Moreover, here we test two alternative filtering criteria in the first simulations based on continuous outcomes (and call this ``LDpred2-auto\_altfilter''). 
First, for prediction, we test filtering on the average of $\boldsymbol{\beta_1}^T \boldsymbol{R} \boldsymbol{\beta_2}$ within each chain, which is an estimate of $r^2$ (cf.\ previous Methods section).
Second, for inference, we filter on some convergence criterion. The split-Rhat statistic is a popular metric to test for good mixing and convergence of Markov chains \cite[]{vehtari2021rank}. 
However, we have found this statistic to perform badly when e.g.\ one parameter gets stuck and is constant; in this case, the chain does not mix well, but a perfect Rhat of 1.0 is obtained. 
Instead, we have found that a two-sample Cramer-von Mises statistic \cite[]{anderson1962distribution}, by similarly using both parts of the chain after burn-in, is often highly correlated with the split-Rhat statistic while not suffering from the previous issue.
We therefore chose to use this statistic, and average the three statistics computed for $h^2$, $p$, and $\alpha$ for each chain. We use a threshold of 4 above which we filter out the chain, because we have found that a value of 4 for this statistic often corresponds to a value close to 1.05 for the split-Rhat.



%\clearpage
\section*{Results}

\subsection*{Validating the inference with simulations}

For simulations, we use the UK Biobank imputed data \cite[]{bycroft2018uk}. We use 356,409 individuals of Northwestern European ancestry and 322,805 SNPs across seven chromosomes (Methods).
We first simulate continuous phenotypes using function \texttt{snp\_simuPheno} from R package bigsnpr \cite[]{prive2017efficient}, varying three parameters: the SNP heritability $h^2$, the polygenicity $p$ (i.e.\ the proportion of causal variants), and the parameter $\alpha$ in equation \eqref{eq:new_model} that controls the relationship between minor allele frequencies and expected effect sizes.
This function first picks a proportion $p$ of causal variants at random, samples effect sizes $\gamma$ using the variance component parameterized by $\alpha$ and then scales the effect sizes so that the genetic component $G \gamma$ has a variance $h^2$, where $G$ is the genotype matrix. Finally, some Gaussian noise is added so that the final phenotype has a variance of 1. 
Then, we run a GWAS to obtain summary statistics using $N$ individuals (either the 200,000 dedicated to this, or a random subset of 20,000), using fast linear regressions implemented in \texttt{big\_univLinReg} from R package bigstatsr \cite[]{prive2017efficient}.
Finally, we run LDpred2-auto with and without the option \texttt{allow\_jump\_sign}, which was proposed in \citep{prive2021identifying} for robustness (when disabled, it prevents effect sizes from changing sign without going through 0 first), and with and without the extended model including a third parameter $\alpha$ (using option \texttt{use\_MLE}, Methods). 
LDpred2-auto is run with 50 Gibbs sampler chains with different starting values for $p$ (from 0.0001 to 0.2, equally spaced on a log scale). Then some of these chains are filtered out for quality control (Methods).

First, LDpred2-auto generally reliably infers the three parameters from its model, i.e.\ the SNP heritability $h^2$, polygenicity $p$, and $\alpha$ (Figures \ref{fig:simu_h2_main}--\ref{fig:simu_alpha_main} and S1--S6).
Compared to LD Score regression, heritability estimates are as precise when power is low, and much more precise when power is large, especially for small polygenicity values (Figures \ref{fig:simu_h2_main}, S1 and S2).
When power is low (e.g.\ $N=20000$ and $h^2=0.01)$, LDpred2-auto\_noMLE (with only two model parameters, as in previous versions of LDpred2-auto) and SBayesS are both over-confident in their estimate of $h^2$ (i.e.\ CIs are small, and do not contain the true parameter value, Figure S7), and LDpred2-auto\_jump overestimates the heritability (Figure S1). LDpred2-auto\_nojump looks very reliable for estimating $h^2$.
When power is low, LDpred2-auto can overestimate the polygenicity when the true value is very small (e.g.\ $p=0.0005$), and underestimate it when the polygenicity is large (e.g.\ $p=0.1$, Figure S3).
SBayesS, which uses a similar model with the same three parameters, often overestimates the polygenicity, especially when $p\le0.02$.
The $\alpha$ estimate of LDpred2-auto (with the extended 3-parameter model) can become very unprecise when power is too low, which can be detected by a small number of chains kept from LDpred2-auto.
Estimates of both $p$ and $\alpha$ from SBayesS are often over-confident with small CIs that do not include the true simulated values (Figures S9 and S11).
Generally, 95\% CIs for all three parameters ($h^2$, $p$ and $\alpha$) obtained from LDpred2-auto\_nojump contain the true simulated value (Figures S7--S12), therefore confirming the validity of these CIs; this is the preferred method we recommend using.
Finally, we also investigate alternative ways of post-filtering chains in LDpred2-auto, for both prediction and inference (LDpred2-auto\_altfilter compared to LDpred2-auto\_nojump, Methods); results remain practically unchanged (Figures S1--S6).

\begin{figure}[!htb]
	\centerline{\includegraphics[width=\textwidth]{est_h2_one_main}}
	\caption{Inferred SNP heritability $h^2$ in simulations with continuous outcomes and N=20K. More results can be found in the Supplementary Materials. Horizontal dashed lines represent the true simulated values. 
		For LDpred2-auto, suffix ``nojump''/``jump'' refers to using \texttt{allow\_jump\_sign = FALSE/TRUE} (and \texttt{use\_MLE = TRUE}), and 
		``noMLE'' refers to using \texttt{use\_MLE = FALSE} (and \texttt{allow\_jump\_sign = FALSE}), and ``altfilter'' is similar to ``nojump'' but uses a different post-filtering of chains (Methods). Note that the recommended option is to use \texttt{allow\_jump\_sign = FALSE} \cite[]{prive2021identifying}.
		The 95\% confidence intervals for the LDpred2-auto and SBayesS estimates are obtained from the 2.5\% and 97.5\% quantiles of all the $h^2$ estimates from the iterations (after burn-in) of the chains kept (note that only one chain is used and kept in SBayesS). The 95\% confidence interval for the LD Score (LDSc) regression estimate is obtained as $\pm$1.96 of its standard error. Colors for LDpred2-auto models represent the number of chains kept (out of 50). \label{fig:simu_h2_main}}
\end{figure}

\begin{figure}[!htb]
	\centerline{\includegraphics[width=\textwidth]{est_p_one_main}}
	\caption{Inferred polygenicity $p$ in simulations with continuous outcomes and N=20K. More results can be found in the Supplementary Materials. Horizontal dashed lines represent the true simulated values. For LDpred2-auto, suffix ``nojump''/``jump'' refers to using \texttt{allow\_jump\_sign = FALSE/TRUE} (and \texttt{use\_MLE = TRUE}), and 
		``noMLE'' refers to using \texttt{use\_MLE = FALSE} (and \texttt{allow\_jump\_sign = FALSE}), and ``altfilter'' is similar to ``nojump'' but uses a different post-filtering of chains (Methods). Note that the recommended option is to use \texttt{allow\_jump\_sign = FALSE} \cite[]{prive2021identifying}. 
		The 95\% confidence intervals for the LDpred2-auto and SBayesS estimates are obtained from the 2.5\% and 97.5\% quantiles of all the $p$ estimates from the iterations (after burn-in) of the chains kept (note that only one chain is used and kept in SBayesS). Colors for LDpred2-auto models represent the number of chains kept (out of 50). \label{fig:simu_p_main}}
\end{figure}

\begin{figure}[!htb]
	\centerline{\includegraphics[width=\textwidth]{est_alpha_one_main}}
	\caption{Inferred $\alpha$ in simulations with continuous outcomes and N=20K. More results can be found in the Supplementary Materials. Horizontal dashed lines represent the true simulated values. Horizontal dotted lines represent boundaries imposed on the LDpred2-auto estimates. For LDpred2-auto, suffix ``nojump''/``jump'' refers to using \texttt{allow\_jump\_sign = FALSE/TRUE} (and \texttt{use\_MLE = TRUE}), and ``altfilter'' is similar to ``nojump'' but uses a different post-filtering of chains (Methods). Note that ``LDpred2\_noMLE'' (\texttt{use\_MLE = FALSE}) does not infer $\alpha$. Note that the recommended option is to use \texttt{allow\_jump\_sign = FALSE} \cite[]{prive2021identifying}. 
		The 95\% confidence intervals for the LDpred2-auto and SBayesS estimates are obtained from the 2.5\% and 97.5\% quantiles of all the $\alpha$ estimates from the iterations (after burn-in) of the chains kept (note that only one chain is used and kept in SBayesS). Colors for LDpred2-auto models represent the number of chains kept (out of 50). \label{fig:simu_alpha_main}}
\end{figure}

Then, LDpred2-auto can also infer per-variant probabilities of being causal and local per-block heritability estimates, which are well calibrated (Figures S13 and S14).
We recall that calibrated per-variant probabilities of being causal (also known as posterior inclusion probabilities, PIPs) can be used for fine-mapping purposes  \cite[]{wang2020simple}.
LDpred2-auto provides PIPs that are more calibrated than with e.g.\ SuSiE-RSS \cite[]{zou2022fine}, which we run assuming there are 10 causal variants per LD block by default (Figure S15).
Finally, LDpred2-auto can also be used to reliably infer the predictive performance $r^2$ of its resulting polygenic score, directly from within the Gibbs sampler (Methods), even when power is low, and we show it works with results from SBayesS's Gibbs sampler as well (Figures S16 and S17).
CIs for this $r^2$ estimate very often encompass the true simulated value, expect for LDpred2-auto\_jump when both $h^2$ and $N$ are small (Figures S18 and S19).

We then run simulations with binary outcomes where the simulated continuous liabilities are transformed to binary outcomes using a threshold corresponding to the prevalence.
Results are very similar as with the continuous phenotypes above (Figures S20--S23), and are similar whether we use either a linear regression GWAS and the total sample size $N$, or a logistic regression GWAS and the effective sample size (i.e.\ $N_\text{eff} = 4 / (1 / N_\text{case} + 1 / N_\text{control})$). The main difference is that the $h^2$ and $r^2$ estimates must be transformed to the liability scale \cite[]{lee2011estimating}, where $K_\text{GWAS}=0.5$ should be used for transforming estimates of $h^2$ and $r^2$ when using $N_\text{eff}$ in inference methods \cite[]{grotzinger2021pervasive}.


\subsection*{Genetic architectures of 248 phenotypes from the UK Biobank}

We use the same 356,409 unrelated individuals of Northwestern European ancestry as in the simulations. 
To form the test set, we randomly select 50,000 of these, while the other 306,409 are used to run a GWAS using linear regression (with function \texttt{big\_univLinReg} from R package bigstatsr) for each of all 248 phenotypes and using eight covariates (Methods).
We first use the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2}.
Here, if not otherwise specified, we use options \texttt{use\_MLE = TRUE} (i.e.\ the extended 3-parameter model and sampling scheme) and \texttt{allow\_jump\_sign = FALSE} (when disabled, this prevents effect sizes from changing sign without going through 0 first and has been proposed for extra robustness in \citep{prive2021identifying}).

Consistent with simulations, inferred SNP heritability $h^2$ estimates from LDpred2-auto closely match with those from LD Score regression, while generally being more precise, especially for phenotypes with a small polygenicity (Figure S24).
Note that these $h^2$ estimates (and later the $r^2$ estimates) have not been transformed to the liability scale (i.e.\ are on the observed scale).
Most phenotypes have an estimated polygenicity $p$ between 0.001 and 0.04; these have therefore a very polygenic architecture, but not an infinitesimal one (Figure S25).
Most phenotypes have an estimated $\alpha$ between -1.0 and -0.3 with a mode at -0.65 (Figure S26).
As for the inferred predictive performance $r^2$ (from the Gibbs sampler of LDpred2-auto, Methods), they are highly consistent with the predictive performance in the test set; only for standing height are they overestimated (Figures \ref{fig:ukbb_r2} and S27). Heritability estimates for height are probably overestimated as well since we use similar formulas for estimating $h^2$ and $r^2$ (Methods), and because the SNP heritability estimate $h^2$ for standing height is higher than values reported in the literature (also see Section ``Application to height''). 

\begin{figure}[!htb]
	\centerline{\includegraphics[width=0.8\textwidth]{ukbb_r2_MLE}}
	\caption{Inferred predictive performance $r^2$ in the UK Biobank. This compares the $r^2$ inferred from the Gibbs sampler of LDpred2-auto (Methods) versus the ones obtained in the test set, for all 248 phenotypes defined from the UK Biobank. These are stratified by the polygenicity estimated from LDpred2-auto. Green dashed lines represent the 1:1 line. The 95\% confidence interval for the LDpred2-auto estimate is obtained from the 2.5\% and 97.5\% quantiles of all the $r^2$ estimates from the iterations (after burn-in) of the chains kept. The 95\% confidence interval for $r^2$ in the test set is obtained from bootstrap. Colors represent the number of chains kept (out of 50). ``F\_height'' and ``M\_height'' use females and males only, respectively (in both GWAS and test sets). \label{fig:ukbb_r2}}
\end{figure}

To investigate whether estimates from LDpred2-auto are robust to some misspecifications, we test using two alternative LD references (Methods).
Using a smaller number of individuals for computing the LD matrix results in a slightly overestimated $p$ and $h^2$ (and $r^2$) with LDpred2-auto, while the $\alpha$ estimate remains consistent, and the predictive performance in the test set remains mostly similar, except for three phenotypes for which none of the LDpred2-auto chains is usable (Figure S28).
When using an LD reference from an alternative population (South Europe instead of North-West Europe), $p$, $h^2$, and $r^2$ are slightly overestimated as well, and a few phenotypes have lower predictive performance while there are four phenotypes for which none of the LDpred2-auto chains is usable (distinct from the previous three, Figure S29).
Interestingly, using the previous approach (\texttt{use\_MLE = FALSE}) seems to provide more robust results, where we can always get some chains not to diverge (and therefore get non-zero predictive performance) for the seven (three and four) phenotypes mentioned before when using the previous alternative LD references (Figure S30).

Then, we investigate the effect of disabling the LDpred2-auto parameter \texttt{allow\_jump\_sign} on the estimates from LDpred2-auto; when disabled, this prevents effect sizes from changing sign without going through 0 first and has been proposed for extra robustness in \citep{prive2021identifying}.
Consistent with simulations, $p$ estimates from LDpred2-auto are conservatively lower than when allowing effects to ``jump'' sign (i.e.\ using a standard sampling, Figure S31). $h^2$ estimates can also be slightly lower, while $\alpha$ estimates are broadly consistent.
As for predictive performance $r^2$ (on the test set), they are similar, suggesting there is no problem of robustness here (when using the N.W. European LD reference) and a standard sampling can be used in this case (Figure S31).

Finally, we investigate different transformations to apply to some continuous phenotypes used here.
Indeed, 49 of the phenotypes used here seem log-normally distributed or heavy-tailed (when visualizing their histogram); we therefore log-transform them.
However, we do investigate alternative transformations here to decide which one should be preferred and to check how this impacts the inference and prediction from LDpred2-auto.
We first compare to using raw (untransformed) phenotypes in Figure S32; estimates of $p$ and $\alpha$ are highly consistent.
However, $h^2$ estimates and predictive performance $r^2$ (in the test set) are generally larger with the log-transformation; it probably makes sense to transform these phenotypes.
We then compare to using the rank-based inverse normal (RIN) transformation in Figure S33; estimates for $p$ and $\alpha$ are also highly consistent.
Except for bilirubin and lipoprotein(a) concentration, higher $h^2$ estimates and predictive performance $r^2$ are generally obtained with the RIN-transformation than the log-transformation.


\subsection*{More heritability and predictive accuracy with the new set of variants}

Here we use the same individuals as in the previous section. We investigate using the extended set of HapMap3 variants proposed here, HapMap3+ (Methods), which includes \textasciitilde37\% more variants on top of HapMap3 variants recommended to use for LDpred2 (i.e.\ 1,054,330 + 389,866 variants), to improve the genome coverage of this set. As expected, compared to HapMap3, higher $h^2$ (average increase of 12.3\% [95\% CI: 10.8, 13.7]) and lower $p$ (decrease of 11.5\% [10.7, 12.3]) estimates are obtained with this extended set HapMap3+ (Figure \ref{fig:hm3_plus}). 
This is consistent with higher predictive performance $r^2$ in the test set (increase of 6.1\% [4.1, 8.2]).
In particular, a much larger $h^2$ estimate is obtained for lipoprotein(a) concentration (0.508 [0.502, 0.514] instead of 0.324 [0.320, 0.329]), which is also reflected in a larger predictive performance ($r^2$ in the test set of 0.516 [0.508, 0.524] instead of 0.344 [0.335, 0.353]).
Interestingly, when using this extended set of HapMap3 variants, more chains are kept on average, which is a sign of better convergence of the models (Figure S34). 
However, running LDpred2 with this extended set of variants takes around 50\% more time; yet, we remind the reader that LDpred2 has been made much faster in \citep{prive2021identifying}, and now runs in less than one hour for 50 chains parallelized over 13 cores (Figure S35), instead of 4--12 hours before.

\begin{figure}[!htb]
	\centerline{\includegraphics[width=0.9\textwidth]{ukbb_compare_hm3_plus}}
	\caption{LDpred2-auto estimates for UKBB phenotypes using either the HapMap3 or HapMap3+ sets of variants. Only 154 phenotypes with more than 25 chains kept when using the HapMap3 variants are represented here. Red dashed lines represent the 1:1 line. The 95\% confidence interval for the LDpred2-auto estimate (in green) is obtained from the 2.5\% and 97.5\% quantiles of all the estimates from the iterations (after burn-in) of the chains kept. The 95\% confidence interval for $r^2$ in the test set is obtained from bootstrap. \label{fig:hm3_plus}}
\end{figure}


\subsection*{Local heritability and polygenicity}

In this section, we use the extended set of variants constructed here, HapMap3+, for which we define 431 independent LD blocks (Methods).
We compute local per-block $h^2$ estimates, and report the UKBB phenotypes for which one block contributes to at least 10\% of the total heritability of all blocks in Figure S36.
For lipoprotein(a) concentration, ``red hair'' and ``disorders of iron metabolism'' (phecode 275.1), almost all heritability comes from one LD block only.
We also perform the same analysis with external GWAS summary statistics for 90 cardiovascular proteins \cite[]{folkersen2020genomic}; 22 (respectively 8) of them have at least 50\% (respectively 80\%) of their heritability explained by a single block (Figure S37). 

Across 169 UKBB phenotypes with more than 25 chains kept, we compute the median heritability per block, and compare it to the number of variants in these blocks; the median heritability explained by a block of variants is largely proportional to the number of variants in this block (Figure S38).
The outlier block explaining a much larger heritability contains the HLA region.
Across the same phenotypes, we then compute per-variant median probabilities of being causal, and report them in a Manhattan-like plot in Figure S39.
Some variants in multiple small regions across the genome have a larger probability of being causal across many phenotypes; interestingly, these are mapped to genes that are known to be associated with many different traits (up to more than 300) in the GWAS Catalog \cite[]{buniello2019nhgri}.
To verify that this is not driven by population structure, we compute pcadapt chi-square statistics that quantify whether a variant is associated with population structure \cite[]{prive2020performing}; the log-statistics have a small negative correlation of -5.5\% with the probabilities of being causal.
To verify that this does not correspond to regions of low LD, we compute LD scores; the median probabilities of being causal have a small correlation of 11.6\% with the LD scores and of -6.8\% with the log of LD scores.

Finally, since the HapMap3+ variants still represent a rather small proportion of common variants, we showcase running LDpred2-auto using a more dense set of variants from a small region, as usually done for fine-mapping.
We identify the most significant HapMap3+ variant for height, rs2871960 on chromosome 3, and read all the variants within a 500kb distance that have a MAF larger than 0.005 and INFO score larger than 0.5 in the UK Biobank; there are 3881 such variants.
Then, we perform a GWAS for these variants using the same 305,338 training individuals as used before (Figure S40).
Finally, using the resulting GWAS summary statistics and an LD reference from the same set of individuals, we run both SuSiE-RSS and LDpred2-auto (\_nojump). We test two different values for L, the maximum number of causal variants in SuSiE-RSS (10 and 100), and three different values for the maximum value of the estimated $p$ (1, 0.01, and 0.001).
Per-variant posterior probabilities of being causal (also known as posterior inclusion probabilities, PIPs) are very similar with both methods, especially when restricting $p$ in LDpred2-auto, which is similar to what SuSiE-RSS assumes (more conservative, Figure S41).


\subsection*{Application to height}

Here we run three LDpred2-auto models for height, one from the same 305K training UKBB individuals used before (with available height, out of 306K), one based on 100K UKBB individuals (as a random subset of the previous 305K), and one from a large GWAS meta-analysis of 1.6M individuals of European genetic ancestries \cite[]{yengo2022saturated}.
We first infer the genetic ancestry proportions of individuals included in the meta-analysis using the method proposed in \citep{prive2021using}, and find that 81.9\% are from N.W. Europe, 9.5\% from E. Europe, 6.5\% from Finland, 1.5\% of Ashkenazi genetic ancestry, 0.3\% from S.W. Europe, and 0.2\% from W. Africa. 
For this set of external GWAS summary statistics, we therefore use the same N.W. European LD matrix as used in UKBB analyses. 
Note that we use the HapMap3+ set of 1,444,196 SNPs here, however, for the GWAS meta-analysis, only 1,013,499 SNPs (out of 1,373,020) are overlapping with HapMap3+ and passing quality control.

As expected \cite[]{loh2018mixed}, intercepts from LD Score regression are increasing with sample size: 1.02 (SE: 0.008) with N=100K, 1.11 (0.015) with N=305K, and 2.31 (0.068) with N=1.6M.
SNP heritability estimates are 64.6\% (SE: 2.7), 59.7\% (2.2), and 39.2\% (1.7) with LD Score regression, respectively, and 60.2\% [95\% CI: 57.2, 63.2], 63.2\% [62.0, 64.4], and 54.2\% [53.9, 54.5] with LDpred2-auto.
As expected, estimated predictive performance $r^2$ (from the Gibbs sampler of LDpred2-auto) are increasing with sample size, with 29.6\% [28.7, 30.5], 42.7\% [42.2, 43.1], and 47.0\% [46.8, 47.1], respectively.
Note that these $r^2$ estimates are probably overestimated by the same margin as the (SNP heritability) $h^2$ estimates, and correspond to \textasciitilde49\%, \textasciitilde67.5\%, and \textasciitilde87\% of $h^2$, respectively.
Even though there are 1.6M individuals in the meta-analysis, the predictive performance corresponds to around 87\% of the SNP heritability only, therefore an even larger sample size is required to be able to better predict height.
Polygenicity estimates from LDpred2-auto are increasing with sample size with 1.2\% [1.0, 1.5], 2.3\% [2.0, 2.5], and 5.9\% [5.6, 6.3], consistent with results of simulations with a large polygenicity (p=10\%). 
Therefore, we estimate that height has at least 50,000 causal variants.
These results are similar irrespective of whether \texttt{allow\_jump\_sign} is used or not, which is surprising to us.
We also identify 1753 SNPs with a probability of being causal larger than 95\% (fine-mapping), which are spread over the entire genome (Figure S42).
As for $\alpha$ estimates from LDpred2-auto, they remain consistent, with -0.71 [-0.75, -0.67], -0.74 [-0.76, -0.72], and -0.78 [-0.82, -0.76], respectively.
Finally, we compute per-annotation heritability estimates from LDpred2-auto results to investigate functional enrichment. We perform this analysis using 50 non-flanking binary annotations from the baselineLD v2.2 model \cite[]{finucane2018heritability}.
Heritability enrichments that we obtain from LDpred2-auto results are rather modest, ranging from 0.7 to 2.5 with a GWAS sample size of N=305K, and of slightly smaller magnitude with N=100K, and of slightly larger magnitude with N=1.6M (Figure S43).


\subsection*{Application to other external GWAS summary statistics}

A description of the eight external GWAS summary statistics used is provided in Table \ref{tab:sumstats}; these do not include UKBB individuals.
Quality control of these summary statistics is performed as described in \citep{prive2021identifying}.
We run LDpred2-auto using either the HapMap3 or HapMap3+ variants, with either the extended or previous model and sampling (via parameter \texttt{use\_MLE}).
Because of the increased mismatch between external GWAS summary statistics and the LD reference we use here (compared to in simulations and UKBB analyses), we also explore multiple values for parameter \texttt{coef\_shrink}, which is a multiplicative coefficient for shrinking/regularizing off-diagonal elements of the LD matrix in LDpred2-auto.
Note that, to transform $r^2$ and $h^2$ estimates to the liability scale (except for vitamin D, which is a continuous trait), we use the prevalence in the UK Biobank as the population prevalence, which may be slightly biased \cite[]{fry2017comparison,van2022reweighting}.
Results are presented in Figure S44.
In terms of predictive performance, using the HapMap3+ variants provides equal or better predictive performance compared to using the HapMap3 variants, except for type 1 diabetes (T1D); therefore it seems more useful to use this new set of variants for larger sample sizes.
Using the extended model and sampling scheme (with option \texttt{use\_MLE}) provides equal or better predictive performance except for vitaminD, but proves to be less robust, especially when using \texttt{coef\_shrink} close to 1 (low or no regularization of the LD matrix). 
The 3-parameter model also generally provides better predictive performance in the UK Biobank analyses, where power and robustness is often not an issue (Figure S45).
Maximum $r^2$ are achieved at different LD regularization coefficients \texttt{coef\_shrink} across phenotypes, reflecting possible substantial mismatches between the GWAS summary statistics and LD reference used.
However, results are virtually unchanged when regularizing the LD matrix (``hm3\_plus\_regul'') by multiplying correlations between variants $i$ and $j$ by $\exp(-0.5 \cdot d_{i,j})$, where $d_{i,j}$ is the distance in cM between the two variants (similarly to as proposed in \citep{wen2010using}), which is surprising to us.
As for estimates of $h^2$ and $r^2$ (inferred from the Gibbs sampler), they tend to increase with smaller values of \texttt{coef\_shrink}. 
This is also the case for estimates of $p$ when using \texttt{use\_MLE = TRUE}.
Estimates of $\alpha$ are largely constant but can become very small (capped at -1.5) in the case of robustness issues when using e.g.\ \texttt{use\_MLE = TRUE} and almost no regularization on the LD matrix (i.e.\ \texttt{coef\_shrink} close to 1).

\begin{table}[!htb]
	\centering
	\begin{tabular}{|l||c|c|c||c|c|}
		\hline
		Trait & GWAS citation & \begin{tabular}{@{}c@{}}Effective GWAS\\sample size\end{tabular} & \# GWAS variants & \begin{tabular}{@{}c@{}}\# matched variants\\with HapMap3+\end{tabular} \\
		\hline
		\hline
		Asthma & \citep{demenais2018multiancestry} & ~~67,341.2 & ~~2,001,280 & ~~~946,092 \\
		Breast cancer (BRCA) & \citep{michailidou2017association} & 254,862.6 & 11,792,542 & 1,411,710 \\
		Coronary artery disease (CAD) & \citep{nikpay2015comprehensive} & 129,014.3 & ~~9,455,778 & 1,325,052 \\
		Depression (MDD) [without UKBB] & \citep{wray2018genome} & 168,040.2 & ~~9,874,289 & 1,314,499 \\
		Prostate cancer (PRCA) & \citep{schumacher2018association} & 135,316.1 & 20,370,946 & 1,411,710  \\
		Type 1 diabetes (T1D) & \citep{censin2017childhood} & ~~13,497.6  & ~~8,996,866 & 1,127,489  \\
		Type 2 diabetes (T2D) & \citep{scott2017expanded} & ~~72,143.0  & 12,056,346 & 1,408,283  \\
		Vitamin D & \citep{jiang2018genome} & ~~79,366~~~ & ~~2,579,296 & 1,028,171 \\
		\hline
	\end{tabular}
	\caption{Summary of external GWAS summary statistics used. These do not include UKBB individuals. Note that some of them may contain a substantial amount of non-European genetic ancestry (e.g.\ >20\% for CAD). \label{tab:sumstats}}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
\section*{Discussion}

LDpred2-auto was originally developed for building polygenic scores \cite[]{prive2020ldpred2}.
Here we have extended the LDpred2-auto model and shown that it can be used to reliably infer genetic architecture parameters such as the SNP heritability (both genome-wide and more locally), polygenicity (and per-variant probabilities of being causal, also known as posterior inclusion probabilities, PIPs, useful for fine-mapping), and the selection-related parameter $\alpha$.
We remind readers that LDpred2 can also be used to infer the uncertainty of individual polygenic scores \cite[]{ding2022large,ding2022polygenic}.
We also introduce a way to infer the out-of-sample predictive performance $r^2$ of the resulting PGS, assuming the target sample has the same genetic ancestry as the GWAS used for training.
Others have proposed to estimate $r^2$ from a reference genotype set \cite[]{mak2017polygenic} or from an additional set of external GWAS summary statistics and LD reference \cite[]{pattee2020penalized,witteveen2022publicly}; here we only use the summary statistics that we input to LDpred2-auto.
Results across 248 phenotypes demonstrate that most of these phenotypes are very polygenic, yet do not have an infinitesimal architecture (i.e.\ not all variants are causal); this is consistent with LDpred2-inf (assuming an infinitesimal architecture, i.e.\ $p=1$) generally providing lower predictive performance than LDpred2-grid (testing different values for parameter $p$) or LDpred2-auto (estimating $p$)\cite[]{prive2020ldpred2}.
We also obtain widespread signatures of negative selection with most $\alpha$ estimates between -1.0 and -0.3 with a mode at -0.65, consistent with previous findings from SBayesS where they find a median S (same as  $\alpha$) of -0.578 (SD: 0.096) \cite[]{zeng2021widespread}.
In that paper, they found consistent results with BayesS, although the original BayesS publication reported weaker effects with a median of -0.37 (SD: 0.11) \cite[]{zeng2018signatures}. In \citep{schoech2019quantification}, they found an average $\alpha$ of -0.38 (SE: 0.02) with GRM-MAF-LD, but they also noted that LDAK estimates were upward biased by 0.4 (originally centered at -0.25 \cite[]{speed2020evaluating}, suggesting a likely value would be close to -0.65, which is what we obtain here).

However, when looking at the heritability enrichments of several functional annotations for height, we obtain much smaller magnitudes with LDpred2-auto than with stratified LD Score regression (S-LDSC)\cite{finucane2018heritability}. For example, \citep{yengo2022saturated} report fold enrichments of more than 10x for e.g.\ coding and conserved variants, while we get less than 2x. 
This is partly due to LDpred2-auto estimates being more conservative as they are shrunk towards no enrichment (the prior), however we do use a very large sample size here so that the prior should not matter much.
Another possible reason comes from using variants that capture the causal effects by LD, while these tagging variants may be annotated differently from the causal variants, which could cause functional enrichments to be diluted \cite[]{zheng2022leveraging}.
We also note that this heritability partitioning is performed after running LDpred2-auto for each annotation independently, therefore, unlike S-LDSC, the LDpred2-auto heritability partitioning does not depend on the set of annotations used. 

Here we have also extended the set of HapMap3 variants recommended to use with LDpred2, making it 37\% larger to offer a better coverage of the genome.
Since we used individuals of diverse ancestries for computing the pairwise variant correlations used for constructing this extended set of variants, this new set of variants is beneficial across diverse ancestries (Methods).
Increasing the genome coverage enables us to capture more of the heritability of phenotypes and therefore reduce the missing heritability, i.e.\ the difference between the family-based heritability and the SNP-based heritability.
Using the new HapMap3+ set also improves predictive performance by an average of 6.1\% in UKBB analyses here, and particularly for lipoprotein(a) concentration with an $r^2$ of 0.516 instead of 0.344.
However, we note that we are able to achieve an $r^2$ of 0.677 [0.671, 0.682] when using the penalized regression implementation of \citep{prive2019efficient} on the UKBB individual-level data while restricting to all variants within a 1Mb window of the \textit{LPA} gene.
This means that this extended SNP set is still not tagging all variants perfectly, and that it might be preferable to use a more localized set of variants for phenotypes for which most of the heritability is contained in a single region of the genome.
When using external GWAS summary statistics, using HapMap3+ instead of HapMap3 variants was more beneficial for larger sample sizes.
Our intuition and conclusion is that using more variants is beneficial when power is sufficient; however, when power is low (e.g.\ small $N$, small $h^2$, and/or large $p$), it may actually be detrimental.

Our proposed method has limitations. First, when power is low (i.e.\ when $N h^2 / p$ is low), estimates of $\alpha$ and $p$ become less reliable.
Therefore, we recommend using the 3-parameter model (with $\alpha$, when using \texttt{use\_MLE = TRUE}), but only when power is sufficient and when robustness is not an issue (e.g.\ without substantial misspecifications such as an ancestry mismatch between the GWAS and LD panels).
We also recommend using option \texttt{allow\_jump\_sign = FALSE} for robustness \cite[]{prive2021identifying}, and for getting accurate or conservative $p$ estimates. When still obtaining a large $p$ estimate ($>1\%$) with this option, we recommend rerunning LDpred2-auto without this option to get a less conservative estimate (cf.\ simulations).
However, LDpred2-auto estimates of $h^2$ and $r^2$ seem always reliable, except for height for which they are probably overestimated.
We think this is likely due to assortative mating, which causes GWAS effects to be inflated \cite[]{border2022assortative,herzig2023model}, which causes our estimates to be inflated as well. 
Second, the $h^2$ from LDpred2-auto is also slightly overestimated when using a small LD reference panel or when the reference panel does not closely match with the ancestry of the GWAS summary statistics.
Future work could focus on correcting these issues.
Third, when using external GWAS summary statistics, it is often beneficial to regularize the LD matrix (via parameter \texttt{coef\_shrink}, especially when using the extended model and sampling), however it leads to an increased estimation for e.g.\ $r^2$ and $h^2$.
Future work could focus on correcting these estimates, and also on identifying the best shrinkage regularization coefficient to apply based on e.g.\ some distance metric (mismatch) between GWAS summary statistics and the LD reference used.
Fourth, because we use a limited set of variants as input for LDpred2, causal variants identified by LDpred2-auto are probably tagging variants that are highly correlated with unobserved causal variants close by. 
LDpred2-auto can also miss some causal variants when they are poorly tagged by the set of variants used.
Future work will focus on scaling LDpred2-auto to using more variants to alleviate this limitation.
LDpred2-auto runtime currently depends on the number of causal variants (or, equivalently, the polygenicity). When the polygenicity is close to 0, it runs linearly with the number of variants. When the polygenicity is close to 1, it runs quadratically. However, the polygenicity is almost always lower than 0.1 for human traits and diseases (cf.\ UKBB results here), which makes running LDpred2-auto efficient (we report runtimes always under one hour, even with HapMap3+ variants).
Currently, the main issue is the large size of the LD matrix that grows quadratically with the number of variants used.
For now, to identify causal variants, one can concentrate on small regions of the genome, where LDpred2-auto can be rerun using a much more dense set of variants, as typically done in fine-mapping analyses (cf.\ Results section ``Local heritability and polygenicity'').

Nevertheless, LDpred2-auto users can now get much from running a single method. The reliable estimates provided by LDpred2-auto are very encouraging to further extend LDpred2-auto in multiple directions. 
As future research directions, we are interested in using LDpred2-auto for GWAS summary statistics imputation \cite[]{rueger2018evaluation,julienne2019raiss}, for genetic correlation estimation \cite[]{bulik2015atlas,shi2017local,speed2019sumher,frei2019bivariate,werme2022integrated}, multi-ancestry prediction and inference \cite[]{brown2016transethnic,shi2020localizing,ruan2022improving,lu2022multi}, as well as extending it to use more variants and to leverage functional annotations \cite[]{zhang2021improved,marquez2021incorporating,zheng2022leveraging}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
\vspace*{3em}

\section*{Acknowledgements}

Authors thank members of the NCRR/QGG StatGen group and Marc-Andr\'e Legault for helpful discussions, as well as reviewers for their useful comments.
Authors also thank GenomeDK and Aarhus University for providing computational resources and support that contributed to these research results.
This research has been conducted using the UK Biobank Resource under Application Number 58024; authors thank all the UK Biobank participants for contributing to such useful data for Research.

F.P., C.A.\ and B.J.V.\ are supported by the Danish National Research Foundation (Niels Bohr Professorship to Prof.\ John McGrath), the Lundbeck Foundation Initiative for Integrative Psychiatric Research, iPSYCH (R102-A9118, R155-2014-1724, R248-2017-2003), and a Lundbeck Foundation Fellowship (R335-2019-2339 to B.J.V.).

\section*{Declaration of Interests}

B.J.V.\ is on Allelica's international advisory board.
The other authors have no competing interests to declare.

\section*{Code and data availability}

The UK Biobank data is available through a procedure described at \url{https://www.ukbiobank.ac.uk/using-the-resource/}. 
UK Biobank received ethical approval from the NHS National Research Ethics Service North West (11/NW/0382). The present analyses were conducted under UK Biobank data application number 58024.
All code used for this paper is available at \url{https://github.com/privefl/paper-infer/tree/main/code}.

\section*{Web Resources}

\noindent Descriptions of UK Biobank phenotypes used here, \url{https://github.com/privefl/paper-infer/blob/main/phenotype-description.tsv}

\noindent Simulation and UKBB results from this study,  \url{https://github.com/privefl/paper-infer/tree/main/results}

\noindent LD matrices for HapMap3+ variants computed from the N.W. European UKBB data used in this paper, \url{https://doi.org/10.6084/m9.figshare.21305061}

\noindent The official tutorial on running LDpred2 with R package bigsnpr (for both prediction and inference), \url{https://privefl.github.io/bigsnpr/articles/LDpred2.html}



%\noindent[TODO: TABLE EXPORTING RESULTS (ESTIMATES)]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\vspace*{3em}
\clearpage

\bibliographystyle{ajhg}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
