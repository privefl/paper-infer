%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{xurl}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}
%\usepackage[font=small]{caption}

\renewcommand{\arraystretch}{1.3}

\usepackage{xr}
\externaldocument{paper-infer-supp}

%\linenumbers
%\doublespacing
\onehalfspacing
\usepackage[authoryear]{natbib}
%\usepackage[numbers,super]{natbib} %\bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{graphicx}
\graphicspath{{../figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\usepackage{algorithm}
\usepackage{algpseudocode}

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother


\begin{document}


\title{Inferring disease architecture and predictive ability\\with LDpred2-auto}
\author{Florian Priv\'e,$^{\text{1,}*}$ Bogdan Pasaniuc,$^{\text{2,3,4,5}}$ and Bjarni J. Vilhj\'almsson$^{\text{1,6}}$}

\date{~ }
\maketitle

\noindent$^{\text{\sf 1}}$National Centre for Register-based Research, Aarhus University, Aarhus, Denmark. \\
\noindent$^{\text{\sf 2}}$Bioinformatics Interdepartmental Program, University of California, Los Angeles, CA. \\
\noindent$^{\text{\sf 3}}$Department of Human Genetics, David Geffen School of Medicine, University of California, Los Angeles, CA. \\
\noindent$^{\text{\sf 4}}$Department of Pathology and Laboratory Medicine, David Geffen School of Medicine, University of California, Los Angeles, CA. \\
\noindent$^{\text{\sf 5}}$Department of Computational Medicine, David Geffen School of Medicine, University of California, Los Angeles, CA. \\
\noindent$^{\text{\sf 6}}$Bioinformatics Research Centre, Aarhus University, Aarhus, Denmark. \\
\noindent$^\ast$To whom correspondence should be addressed. \\

\noindent Contact: \url{florian.prive.21@gmail.com}

%\vspace*{6em}
\clearpage

\begin{abstract}

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Introduction}

Most traits and diseases are heritable, if not all. 
What differs is the proportion of phenotypic variance that can be attributable to genetics, i.e.\ the heritability of these phenotypes.
Some phenotypes, such as height and schizophrenia are highly heritable [TODO: ADD CITATIONS]. 
These two phenotypes are also highly polygenic, i.e.\ mutations from many genetic variants influences them [TODO: ADD CITATIONS].
Knowing how much a phenotype is heritable and polygenic can teach a lot about it.
Therefore, many methods have been developed to estimate the (SNP) heritability $h^2$ and polygenicity $p$.
These include GCTA ($h^2$), BOLT-REML ($h^2$ and $p$), LD Score regression ($h^2$), HESS (local $h^2$), LDAK-SumHer ($h^2$), S-LD4M ($p$), GRM-MAF-LD ($\alpha$ that can inform about negative selection), SBayesS ($h^2$, $p$, and a third parameter $S$, similar to $\alpha$), BEAVR (local $p$) \cite[]{yang2011gcta,loh2015contrasting,bulik2015ld,shi2016contrasting,speed2019sumher,oconnor2019extreme,schoech2019quantification,zeng2021widespread,johnson2021estimation}.

These two parameters are useful e.g.\ to determine how well we can predict a phenotype from using genetic variants alone [TODO: ADD CITATIONS]. 
Such genetic predictors are called polygenic scores (PGS), and are getting closer to be included as part of existing clinical risk models for diseases [TODO: ADD CITATIONS].
LDpred2 is a very competitive polygenic score method that can directly builds PGS using summary statistics results from genome-wide associations studies (GWAS), making it highly applicable \cite[]{prive2020ldpred2,pain2021evaluation,kulm2021systematic}.
LDpred2 uses the (SNP) heritability and polygenicity as parameters of its model. In LDpred2-auto, it can directly estimate these parameters from the data, making it applicable even when no validation data is available for tuning these two hyper-parameters of the model \cite[]{prive2020ldpred2}.

Here we extend LDpred2-auto to make it a highly reliable method for estimating (local) $h^2$, (per-variant) $p$, and $\alpha$.
We show that we can also reliably estimate the predictive ability of PGS derived from LDpred2-auto.

[TO FINISH]

[ALSO TALK ABOUT NEW SET OF VARIANTS]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

[OVERVIEW TABLE OF WHAT LDPRED2 CAN PROVIDE?]


\section*{Results}

\subsection*{Validating the inference with simulations}

For simulations, we use the UK Biobank imputed data \cite[]{bycroft2018uk}; we use 356,409 individuals of Northwestern European ancestry and 322,805 SNPs across seven chromosomes (Methods).
We first simulate continuous phenotypes using function \texttt{snp\_simuPheno} from R package bigsnpr \cite[]{prive2017efficient}, varying three parameters: the SNP-heritability $h^2$, the polygenicity $p$ (i.e. the proportion of causal variants), and the parameter $\alpha$ in equation \eqref{eq:new_model} that controls the relationship between minor allele frequencies and expected effect sizes.
This function first picks a proportion $p$ of causal variants at random, sample effect sizes $\gamma$ using the variance component parameterized by $\alpha$ and then scale the effect sizes so that the genetic component $G \gamma$ has a variance $h^2$, where $G$ is the genotype matrix. Finally, some Gaussian noise is added so that the full phenotype has a variance of 1. 
Then, a GWAS is run to obtain summary statistics using $N$ (either the 200,000 dedicated to this, or a subset of 20,000) individuals using a simple linear regression implemented in \texttt{big\_univLinReg} from R package bigstatsr \cite[]{prive2017efficient}.
Finally, we run the new LDpred2-auto model (Methods) with and without the option \texttt{allow\_jump\_sign}, which was proposed in \cite{prive2021identifying} for robustness (when disabled). 
LDpred2-auto is run with 50 Gibbs sampler chains with different starting values for $p$.

LDpred2-auto generally reliably infers the three parameters from its model, i.e.\ the SNP heritability $h^2$, polygenicity $p$, and $\alpha$ (Figures \ref{fig:simu_h2},\ref{fig:simu_p} and \ref{fig:simu_alpha}).
Moreover, LDpred2-auto can also infer per-variant probabilities of being causal and per-block (local) heritability estimates that are well calibrated (Figures \ref{fig:simu_postp_calib} and \ref{fig:simu_h2_calib}).
Finally, LDpred2-auto can be used to infer the predictive performance $r^2$ of its resulting polygenic score, directly from within the Gibbs sampler (Figure \ref{fig:simu_h2}).
[TODO: TALK ABOUT WHERE IT FAILED AND LIMITATIONS]
[TODO: RUN AND REPORT THE MEAN]

We also run simulations with binary outcomes where the simulated continuous liabilities are transformed to binary outcomes using a thresholding corresponding to the prevalence [TODO: MAYBE REWORD].
Results are very similar as with the continuous phenotypes above, and are similar whether we use either a linear regression GWAS and the total sample size $N$, or a logistic regression GWAS and the effective sample size (i.e.\ $N_\text{eff} = 4 / (1 / N_\text{case} + 1 / N_\text{control})$). The only difference is the transformation to the liability scale that needs to be applied to the $h^2$ and $r^2$ estimates from LDpred2-auto, where $K_\text{GWAS}=0.5$ should be used when using $N_\text{eff}$ \cite[]{grotzinger2021pervasive}.
 [TO FINISH]
 

\subsection*{Genetic architectures of 248 phenotypes from the UK Biobank}

We use the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2}, and the same 356,409 unrelated individuals of Northwestern European ancestry as in the simulations. 
50,000 of these will be used as test set, while the other 306,409 are used to run a GWAS using linear regression (function \texttt{big\_univLinReg}) for each of all 248 phenotypes and using 8 covariates (Methods).
Then the new implementation of LDpred2-auto (Methods) is used.

Consistent with simulations, inferred SNP heritability $h^2$ estimates from LDpred2-auto closely match with those from LD Score regression, while generally being more precise, especially for phenotypes with a smaller polygenicity (Figure \ref{fig:ukbb_h2}).
Note that these $h^2$ estimates (and later the $r^2$ estimates) have not been transformed to the liability scale (i.e.\ are on the observed scale).
Most phenotypes have an estimated polygenicity $p$ between 0.001 and 0.04; these have therefore a very polygenic architecture, but not an infinitesimal one (Figure \ref{fig:ukbb_h2_p}).
Most phenotypes have an estimated $\alpha$ between -1.0 and -0.4 with a mode at -0.65 (Figure \ref{fig:ukbb_h2_alpha}), which is consistent with widespread negative selection.
As for the inferred predictive performance, they are highly consistent with the ones derived from the test; only for standing height and sitting height are they slightly overestimated (Figure \ref{fig:ukbb_r2}). Heritability estimates for these two traits are probably slightly overestimated as well since we use similar formulas for estimating $h^2$ and $r^2$, and these are higher than values reported in the literature. 

We then investigate previous estimates using two alternative LD references (Methods).
Using a smaller number of individuals for computing the LD results in a slightly overestimated $p$ and $h^2$ (and $r^2$), while the $\alpha$ estimate remains consistent, and the predictive performance in the test set remains mostly similar (Figure \ref{fig:small_LD}).
When using an LD reference from an alternative population (South Europe instead of North-West Europe), $p$, $h^2$, and $r^2$ are slightly overestimated as well, and a few phenotypes have lower predictive performance (Figure \ref{fig:alt_LD}).

We then investigate previous estimates using the extended set of HapMap3 variants proposed here (Methods). As expected, compared to HapMap3, higher $h^2$ (average increase of 12.3\% [10.8-13.7]) and lower $p$ (decrease of 11.5\% [10.6-12.3]) estimates are obtained with this extended set HapMap3+ (Figure \ref{fig:hm3_plus}). 
This is consistent with higher predictive performance $r^2$ in the test set (increase of 6.1\% [4.1-8.2]).
A particularly much larger $h^2$ estimate is obtained for lipoprotein(a) concentration (0.508 [0.502-0.514] instead of 0.324 [0.320-0.329]), which is also reflected in a larger predictive performance ($r^2$ in test set of 0.516 [0.508-0.524] instead of 0.344 [0.335-0.353]).
Interestingly, when using this extended set of variants, more chains are kept on average, which is a sign of better convergence of the models (Figure \ref{fig:ukbb_chains}). 
However, fitting with this extended set of variants is more computationally demanding [TODO RATIO]; yet, we recall that LDpred2 has been made much faster in \cite{prive2021identifying}, and now run in less than one hour for 50 chains parallelized over 13 cores (Figure \ref{fig:ukbb_runtimes}).

Finally, we investigate different transformations to apply to some continuous phenotypes used here.
Indeed, 49 of such phenotypes seems log-normally distributed or heavy-tailed (when visualizing their histogram); we therefore log-transform them.
However, we do investigate alternative transformations here to decide which one should be preferred and to check the impact on the inference from LDpred2-auto.
Note that we use the HapMap3+ set of variants here.
We first compare to using raw (untransformed) phenotypes in Figure \ref{fig:notransfo}; estimates for $p$ and $\alpha$ are highly consistent.
However, $h^2$ estimates and predictive performance $r^2$ (in the test set) are generally larger with the log-transformation, hinting that it probably makes sense to transform these phenotypes.
We then compare to using the rank-based inverse normal (RIN) transformation in Figure \ref{fig:RINT}; estimates for $p$ and $\alpha$ are also highly consistent.
Except for bilirubin and lipoprotein(a) concentration, generally higher $h^2$ estimates and predictive performance $r^2$ are obtained with the RIN-transformation than the log-transformation.


\subsection*{Local heritability and poligenicity}

In this section, we use the new HapMap3+ set of variants constructed here. 
We recall that we have defined 431 independent LD blocks for this set (Methods).
We compute a per-block (local) $h^2$ estimate, and report the UKBB phenotypes for which one block contributes to at least 10\% of the total heritability of all blocks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Discussion}


[KEEP RG FOR DISCU + CITE EXISTING METHODS]

[BETTER SET OF VARIANTS, BUT STILL NOT PERFECT E.G. FOR PROTEIN LEVELS]

[ALSO TALK ABOUT IMPUTATION]

[ALSO TALK ABOUT LDSC?]

[FUTURE WORK + LIMITATION: OVERESTIMATED H2 WITH SMALL LD + NEED TO WORK ON CORRECTION]

[ASSORTATIVE MATING FOR HEIGHT?]

[VERY POLYGENIC, BUT NOT INFINITESIMAL -> THEREFORE LDPRED2-INF NEVER RECOMMENDED (LDPRED2 + MISSPEC)]

[HM3\_PLUS AND MISSING HERITABILITY]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Materials and Methods}

\subsection*{Data for simulations}

For simulations, we use the UK Biobank imputed (BGEN) data, read as allele dosages with function \texttt{snp\_readBGEN} from R package bigsnpr \cite[]{bycroft2018uk,prive2017efficient}. 
We use the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2}.
Since we run lots of different models, we restrict the simulations to chromosomes 3, 6, 9, 12, 15, 18 and 21, resulting in a set of 322,805 SNPs.
We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of \citet{bycroft2018uk}).
To get a set of genetically homogeneous individuals, we compute a robust Mahalanobis distance based on the first 16 PCs (field 22009) and further restrict individuals to those within a log-distance of 4.5 \cite[]{prive2020efficient}.  
This results in 356,409 individuals of Northwestern European ancestry.
We randomly sample 200,000 individuals to form a training set (to run the GWAS), and use the remaining individuals to form a test set (to evaluate the predictive models).

\subsection*{Data for the UK Biobank analyses}

We use the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2}, and the same 356,409 individuals of Northwestern European ancestry as in the simulations.
We randomly sample 50,000 individuals to form a test set (to evaluate the predictive models), and use the remaining individuals to form a training set (to run the GWAS).

We construct and use the same phenotypes as in \cite{prive2021high}. About half of these consists of phecodes mapped from ICD10 and ICD9 codes using R package PheWAS \cite[]{carroll2014r,wu2019mapping}.
The other half consists of phenotypes defined in UKBB fields based on manual curation \cite[]{prive2021high}.
As covariates, for the subset of individuals previously defined, we first recompute PCs using function \texttt{snp\_autoSVD} from R package bigsnpr and keep four PCs based on visual inspection \cite[]{prive2017efficient,prive2020efficient}. We also use sex (field 22001), age (field 21022), birth date (combining fields 34 and 52) and deprivation index (field 189) as additional covariates.


We use the LD matrix with independent LD blocks computed in \cite{prive2021identifying}.
We design two other LD matrices: one using a smaller subset of 2000 individuals from the previously selected ones (which we call ``hm3\_small''), and one based on 10,000 individuals from around South Europe by using the ``Italy'' center defined in \cite{prive2021high} (``hm3\_altpop'').
We apply the optimal algorithm developed in \cite{prive2021optimal} to obtain independent LD blocks, as recommended in \cite{prive2021identifying}.
We finally define a fourth LD reference by extending the set of HapMap3 variants (see next Methods section) and using 20,000 individuals from the previously selected ones (``hm3\_plus'').

\subsection*{Extending the set of HapMap3 variants used}

The HapMap3 variants generally provide a good coverage of the whole genome.
We recall that the set of 1,054,330 HapMap3 variants recommended to use for LDpred2 \cite[]{prive2020ldpred2} is a subset of the original set of HapMap3 variants, which does not include duplicated positions (e.g.\ multi-allelic variants), nor ambiguous variants (e.g.\ both 'A' and 'T' or 'C' and 'G'), and which includes SNPs only (e.g.\ no indel).
Here we propose to extend the set we have used for LDpred2 until then. 
This extension aims at making sure many genetic variants are well tagged by the extended set.
To design this new set, we first read all variants from the UK Biobank (UKBB) with a minor allele frequency (MAF) larger than 0.005 in the whole data (i.e.\ the MAF from the MFI files). 
We then compute all pairwise correlations between variants within a 1 Mb distance, restricting to squared correlations larger than 0.3, and using all unrelated UKBB individuals excluding all White British (field 22006) to have a set of individuals from diverse ancestries.
Finally, we design an algorithm which aims at maximizing the tagging of all these variants read. We want to maximize $\sum_j \max_{k \in \text{HapMap3+}} r_{j,k}^2$, where $j$ spans the whole set of variants read, while $k$ spans the variants kept in the new set, which we call HapMap3+.
We start by including all previously used HapMap3 variants.
Then, for the sake of simplicity, we use a greedy approach, where we repeatedly include the variant which increases this sum most, until no variant improves it by more than 2. 
Note that we only allow non-ambiguous SNPs to be included.
This results in an extended set of 1,444,196 SNPs, of which we compute the correlation between variants (within a 3 cM window) and apply the optimal algorithm developed in \cite{prive2021optimal} to obtain 431 independent LD blocks.

[FURTHER RESTRICT VARIANTS THAT CAN ENTER THIS NEW SET?]

\subsection*{New model and inference with LDpred2-auto}

LDpred2 originally assumed the following model for effect sizes,
\begin{equation}\label{eq:prev_model}
\beta_j = S_j \gamma_j \sim \left\{
\begin{array}{ll}
\mathcal N\left(0,~\dfrac{h^2}{M p}\right) & \mbox{with probability $p$,} \\
0 & \mbox{otherwise,}
\end{array}
\right.
\end{equation}
where $p$ is the proportion of causal variants, $M$ the number of variants, $h^2$ the (SNP) heritability, $\gamma$ the effect sizes on the allele scale, $S$ the standard deviations of the genotypes, and $\beta$ the effects of the scaled genotypes \cite[]{prive2020ldpred2}.
In LDpred2-auto, $p$ and $h^2$ are directly estimated within the Gibbs sampler, as opposed to testing several values of $p$ and $h^2$ from a grid of hyper-parameters. This makes LDpred2-auto a method free of hyper-parameters which can therefore be applied directly to data without the need of a validation dataset to choose best-performing hyper-parameters \cite[]{prive2020ldpred2}.
Previously, $p$ was sampled from $\text{Beta}(1 + M_c, 1 + M - M_c)$, where $M_c = \sum_j(\beta_j \neq 0)$.

Here we introduce a few changes to LDpred2-auto, which makes it better at inferring these important parameters.
First, we extend LDpred2-auto with a third parameter $\alpha$ that controls the relationship between minor allele frequencies (or equivalently, standard deviations) of genotypes and expected effect sizes; the model becomes
\begin{equation}\label{eq:new_model}
\beta_j = S_j \gamma_j \sim \left\{
\begin{array}{ll}
\mathcal N \big( 0,~\sigma_\beta^2 \cdot (S_j^2)^{(\alpha + 1)} \big) & \mbox{with probability $p$,} \\
0 & \mbox{otherwise.}
\end{array}
\right.
\end{equation}
Therefore, it was earlier assumed that $\alpha = -1$ and $\sigma_\beta^2 = h^2 / (M p)$ in equation \eqref{eq:prev_model}. 
This new model in equation \eqref{eq:new_model} is similar to the model assumed by SBayesS, where $\alpha$ is called $S$ \cite{zeng2021widespread}. 
In SBayesS, they estimate $\alpha$ and $\sigma_\beta^2$ by maximizing the likelihood of the normal distribution (over the causal variants from the Gibbs sampler).
In the new LDpred2-auto, we first sample causal variants with replacement (bootstrap) before computing the maximum likelihood estimators, such that we add some proper sampling to these two parameters. 
This maximum likelihood estimation is implemented using R package roptim \cite[]{pan2020roptim}, and we bound the estimate of $\alpha$ to be between -1.5 and 0.5 (the default, but can be modified), and the estimate of $\sigma_\beta^2$ to be between 0.5 and 2 times the one from the previous iteration.
We now sample $p$ from $\text{Beta}(1 + M_c / \bar{l^2}, 1 + (M - M_c) / \bar{l^2})$, where $\bar{l^2}$ is the average LD score, to add more sampling by properly accounting for the reduced effective number of correlated variants.
As for $h^2$, we still estimate it by $h^2 = \boldsymbol{\beta}^T \boldsymbol{R} \boldsymbol{\beta}$, where $\boldsymbol{R}$ is the correlation matrix between variants and $\boldsymbol{\beta}$ is a vector of causal effect sizes (after scaling) from one iteration of the Gibbs sampler. 
We constrain this estimate to be at least 0.001 to prevent the Gibbs sampler from being trapped in very small heritability estimates.
Note that this $h^2$ estimate can be restricted to e.g.\ variants from a single LD block to get estimates of local heritability.

\subsection*{Inference of predictive performance from the Gibbs sampler}

[TODO: EXPLAIN HOW TO INFER R2]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\clearpage
%\vspace*{3em}

\section*{Acknowledgements}

Authors thank members of the NCRR/QGG StatGen group for helpful discussions.
Authors also thank GenomeDK and Aarhus University for providing computational resources and support that contributed to these research results.
This research has been conducted using the UK Biobank Resource under Application Number 58024; authors thank all the participants of the UK Biobank for contributing to such useful data for Research.

\section*{Funding}

F.P.\ and B.J.V.\ are supported by a Lundbeck Foundation Fellowship (R335-2019-2339 to B.J.V.).

\section*{Declaration of Interests}

B.J.V.\ is on Allelica's international advisory board.
The other authors have no competing interests to declare.

\section*{Code and data availability}

The UK Biobank data is available through a procedure described at \url{https://www.ukbiobank.ac.uk/using-the-resource/}. 
All code used for this paper is available at \url{https://github.com/privefl/paper-infer/tree/master/code}.
We have extensively used R packages bigstatsr and bigsnpr \cite[]{prive2017efficient} for analyzing large genetic data, packages from the future framework \cite[]{bengtsson2020unifying} for easy scheduling and parallelization of analyses on the HPC cluster, and packages from the tidyverse suite \cite[]{wickham2019welcome} for shaping and visualizing results.
The latest version of R package bigsnpr can be installed from GitHub.%, and a recent enough version can be installed from CRAN [TODO: VERIFY].

[TODO: TABLE EXPORTING RESULTS (ESTIMATES)]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
%\vspace*{3em}

\bibliographystyle{natbib}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
